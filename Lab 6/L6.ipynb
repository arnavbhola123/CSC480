{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364ef75b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# CSC 480-F25 Lab 6: Knowledge Graphs\n",
    "\n",
    "### Author:\n",
    "***Arnav Bhola, Pranav Krishna***\n",
    "\n",
    "California Polytechnic State University, San Luis Obispo;\n",
    "Computer Science & Software Engineering Department\n",
    "\n",
    "### Overview\n",
    "\n",
    "This lab covers Knowledge Graphs with Neo4j—from standing up a local graph database and writing basic Cypher, to designing a practical schema with constraints and indexes, then (optionally) using an agentic system to help plan and create that schema. You’ll work with a small investigative dataset (people, events, locations, evidence, and cases) and translate flat CSVs into a connected graph that supports rich querying and reasoning.\n",
    "\n",
    "Specifically, you will:\n",
    "- Install and connect to Neo4j Desktop; verify connectivity using the Python driver.\n",
    "- Inspect the provided CSVs and understand how entities (nodes) and relations (edges) map to a graph model.\n",
    "- Create an example schema via Cypher with unique constraints and helpful indexes, using a provided helper for executing queries.\n",
    "- Optionally, invoke an AutoGen-based agentic workflow (Azure OpenAI) to propose and materialize the schema automatically.\n",
    "- Prepare the knowledge graph you’ll query and reason over in the next lab.\n",
    "\n",
    "By the end, you should be able to model a domain as a graph, set up constraints and indexes to keep it clean and fast, load/validate data with Cypher, and set the stage for reasoning and querying in Lab 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea034b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting up Neo4j (Desktop)\n",
    "\n",
    "### Installation\n",
    "\n",
    "Follow the instructions at this [link](https://neo4j.com/docs/desktop/current/installation/). Install version 2.0.5 for whatever OS your system uses. You'll have to create an account.\n",
    "\n",
    "### Creating a Graph DB with Neo4j desktop\n",
    "\n",
    "Open the Neo4j desktop application and follow the directions to create your first Neo4j instance.\n",
    "This instance acts as your DBMS, which manages Graph DBs.\n",
    "Then, follow the instructrions [here](https://neo4j.com/docs/desktop/current/operations/database-management/) to create and host a Graph DB on your system with local host. When you create a DB you'll be prompted to create a password for the DB. It can be as simple as you'd like, as it's only accessible by users on your system, but you need to remember it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c566f4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/5c/bd/bf8064d9cfa214294356c2d6702b716d3cf3bb24be59287a6a21e24cae6b/pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting neo4j\n",
      "  Obtaining dependency information for neo4j from https://files.pythonhosted.org/packages/75/4e/11813da186859070b0512e8071dac4796624ac4dc28e25e7c530df730d23/neo4j-6.0.2-py3-none-any.whl.metadata\n",
      "  Downloading neo4j-6.0.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting neomodel\n",
      "  Obtaining dependency information for neomodel from https://files.pythonhosted.org/packages/09/c6/24e4832b810f6dfd6473adfb6d5a833ce57d04da4ccf95613b1c3fa5f7d7/neomodel-5.5.3-py3-none-any.whl.metadata\n",
      "  Downloading neomodel-5.5.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: autogen-core in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (0.7.5)\n",
      "Requirement already satisfied: autogen-agentchat in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (0.7.5)\n",
      "Requirement already satisfied: autogen-ext[azure,openai] in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (0.7.5)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.26.0 from https://files.pythonhosted.org/packages/c7/e4/0a94b09abe89e500dc748e7515f21a13e30c5c3fe3396e6d4ac108c25fca/numpy-2.3.4-cp312-cp312-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading numpy-2.3.4-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting neo4j\n",
      "  Obtaining dependency information for neo4j from https://files.pythonhosted.org/packages/04/00/1f74089c06aec1fac9390e2300a6a6b2381e0dac281783d64ccca9d681fd/neo4j-5.28.2-py3-none-any.whl.metadata\n",
      "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (1.37.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (11.3.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (2.11.9)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-core) (4.15.0)\n",
      "Requirement already satisfied: azure-ai-inference>=1.0.0b9 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (1.0.0b9)\n",
      "Requirement already satisfied: azure-ai-projects>=1.0.0b11 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (1.1.0b4)\n",
      "Requirement already satisfied: azure-core in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (1.35.1)\n",
      "Requirement already satisfied: azure-identity in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (1.25.0)\n",
      "Requirement already satisfied: azure-search-documents>=11.4.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (11.5.3)\n",
      "Requirement already satisfied: aiofiles in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (24.1.0)\n",
      "Requirement already satisfied: openai>=1.93 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (2.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from autogen-ext[azure,openai]) (0.11.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-ai-inference>=1.0.0b9->autogen-ext[azure,openai]) (0.7.2)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai]) (12.26.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.2.0b3 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai]) (1.2.0b5)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-core->autogen-ext[azure,openai]) (2.32.5)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-core->autogen-ext[azure,openai]) (1.17.0)\n",
      "Requirement already satisfied: azure-common>=1.1 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-search-documents>=11.4.0->autogen-ext[azure,openai]) (1.1.28)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.67.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.34.1->autogen-core) (8.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from tiktoken>=0.8.0->autogen-ext[azure,openai]) (2025.9.18)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-identity->autogen-ext[azure,openai]) (46.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-identity->autogen-ext[azure,openai]) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from azure-identity->autogen-ext[azure,openai]) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.93->autogen-ext[azure,openai]) (3.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.0.0)\n",
      "Requirement already satisfied: certifi in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core) (3.23.0)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from msal>=1.30.0->azure-identity->autogen-ext[azure,openai]) (2.10.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (2.5.0)\n",
      "Requirement already satisfied: pycparser in /Users/arnavbhola/CSC480/.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.23)\n",
      "Downloading pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading neomodel-5.5.3-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, numpy, neo4j, pandas, neomodel\n",
      "Successfully installed neo4j-5.28.2 neomodel-5.5.3 numpy-2.3.4 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas neo4j neomodel \"autogen-core\" \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170a122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! Result: 1\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that the database is set up correctly\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "username = \"neo4j\"  # the default user created when you set up Neo4j\n",
    "password = \"RandomPassword\"  # example password\n",
    "hostname = \"127.0.0.1\"\n",
    "port = 7687  # default Bolt protocol port\n",
    "uri = f\"bolt://{hostname}:{port}\"\n",
    "\n",
    "# Test with the native neo4j driver to see if we get more details\n",
    "try:\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 1 as test\")\n",
    "        print(f\"Connection successful! Result: {result.single()['test']}\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2155a92",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  L6-7_data.zip\n",
      " extracting: ./L6-7_data/Case.csv    \n",
      "  inflating: ./L6-7_data/Case_Related_Rel.csv  \n",
      "  inflating: ./L6-7_data/Event.csv   \n",
      "  inflating: ./L6-7_data/Event_Evidence_Location_Rel.csv  \n",
      "  inflating: ./L6-7_data/Evidence.csv  \n",
      "  inflating: ./L6-7_data/Location.csv  \n",
      "  inflating: ./L6-7_data/Person.csv  \n",
      "  inflating: ./L6-7_data/Person_Location_Rel.csv  \n",
      "  inflating: ./L6-7_data/Person_Person_Rel.csv  \n"
     ]
    }
   ],
   "source": [
    "# Extract the data files\n",
    "!unzip -o L6-7_data.zip -d ./L6-7_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05dc0d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### L6-7_data: High-level dataset breakdown\n",
    "\n",
    "This dataset models the Kristin Smart case with clearly separated node CSVs (entities) and relationship CSVs (edges), using Neo4j-style import headers. Here’s the global picture and what each file contributes.\n",
    "\n",
    "#### Entities (nodes)\n",
    "\n",
    "- Person.csv\n",
    "  - Key columns: `id`, `name`, `type`, `status`, `dob`\n",
    "  - Examples: KS (Kristin Smart – Victim), PF (Paul Flores – Suspect/Murderer), RF (Ruben Flores – Accessory), family and witnesses.\n",
    "  - Notes: `type` captures role (Victim, Suspect, Family, Witness); `status` captures lifecycle (e.g., Convicted, Deceased, Key Witness).\n",
    "\n",
    "- Location.csv\n",
    "  - Key columns: `id`, `name`, `type`, `address`, `city`\n",
    "  - Examples: PARTY_LOC (Crandall Way party house), MUIR_HALL, SANTA_LUCIA (dorms), RF_HOME, PF_HOME_LA, EXCAVATION_16 (dig site), MONTEREY_COURT.\n",
    "  - Notes: `type` distinguishes residences, dorms, search sites, and venues.\n",
    "\n",
    "- Event.csv\n",
    "  - Key columns: `id`, `type`, `date`, `description`\n",
    "  - Examples: DISAPPEAR (last sighting), DECLARE_DEAD, DIG_2016, SEARCH_RF_HOME, ARRESTS, TRIAL_START, PF_GUILTY.\n",
    "  - Notes: Seminal milestones with dates and human-readable descriptions.\n",
    "\n",
    "- Evidence.csv\n",
    "  - Key columns: `id`, `type`, `status`, `description`\n",
    "  - Examples: EARING (lost by police), TRUCKS (seized/analyzed), DRUGS (found at PF_HOME_LA), BIOLOGICAL (under RF deck), VOLKSWAGEN, VIDEOS.\n",
    "  - Notes: `status` reflects chain-of-custody or analysis (Seized/Analyzed, Unknown, etc.).\n",
    "\n",
    "- Case.csv\n",
    "  - Key columns: `id`, `name`, `status`, `dateOpened`\n",
    "  - Example: CASE_KS (Murder of Kristin Smart; status shows conviction and the case open date).\n",
    "\n",
    "#### Relationships (edges)\n",
    "\n",
    "- Person_Person_Rel.csv (Person → Person)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Person)`, `:TYPE`, `relationshipType`\n",
    "  - Examples: `ACCOMPANIED_BY` (who walked with whom), `FAMILY_RELATIONSHIP` (e.g., PF → RF Father).\n",
    "  - Notes: `relationshipType` adds semantic detail (e.g., \"Last Known Person\", \"Spouse\").\n",
    "\n",
    "- Person_Location_Rel.csv (Person → Location)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Location)`, `:TYPE`, `date`, `time`\n",
    "  - Examples: `ATTENDED_PARTY_AT` (KS/PF/others → PARTY_LOC), `LAST_SEEN_NEAR` (KS → SANTA_LUCIA), `LIVED_AT`/`RESIDENCE_OF` for dorm/home ties.\n",
    "  - Notes: `date`/`time` may be missing for some records; treat as optional properties.\n",
    "\n",
    "- Event_Evidence_Location_Rel.csv (Evidence → Location)\n",
    "  - Columns: `Event_Evidence_Location_Rel:START_ID`, `:END_ID`, `:TYPE`, `date`\n",
    "  - Examples: `FOUND_AT` (BIOLOGICAL → RF_HOME), `SEIZED_FROM` (VOLKSWAGEN/DRUGS/VIDEOS → RF_HOME/PF_HOME_LA) with dates.\n",
    "  - Notes: Despite the header name, the `START_ID` values correspond to Evidence IDs (e.g., DRUGS, VOLKSWAGEN). Use as Evidence → Location.\n",
    "\n",
    "- Case_Related_Rel.csv (Person → Case)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Case)`, `:TYPE`, `outcome`\n",
    "  - Examples: `VICTIM_IN` (KS → CASE_KS), `SUSPECT_IN` (PF → CASE_KS, outcome=Convicted), `ACCUSED_IN` (RF → CASE_KS, outcome=Acquitted), `FILED_CIVIL_SUIT_IN` (family → CASE_KS).\n",
    "  - Notes: `outcome` is optional and captures legal results when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781c0308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Evidence.csv\n",
      "Dataframe head:           id                 type                           status  \\\n",
      "0      EARING         Lost Earring  Status Unknown (Lost by police)   \n",
      "1      TRUCKS  Paul Flores' Trucks                  Seized/Analyzed   \n",
      "2       DRUGS      Date Rape Drugs                           Seized   \n",
      "3  BIOLOGICAL  Biological Evidence           Analyzed (Human Blood)   \n",
      "4  VOLKSWAGEN    1985 VW Cabriolet                  Seized/Analyzed   \n",
      "5      VIDEOS      Homemade Videos                  Seized/Analyzed   \n",
      "\n",
      "                                         description  \n",
      "0          Found at former residence of PF's mother.  \n",
      "1  Two trucks owned by PF were taken as evidence ...  \n",
      "2  Found during search of Paul Flores' San Pedro ...  \n",
      "3    Found in soil samples under Ruben Flores' deck.  \n",
      "4  Towed from Ruben Flores' home after cadaver do...  \n",
      "5  Showing PF with other women, used to establish...  \n",
      "==========================================================================================\n",
      "\n",
      "File: Event_Evidence_Location_Rel.csv\n",
      "Dataframe head:  Event_Evidence_Location_Rel:START_ID     :END_ID        :TYPE        date\n",
      "0                           BIOLOGICAL     RF_HOME     FOUND_AT  2021-03-15\n",
      "1                           VOLKSWAGEN     RF_HOME  SEIZED_FROM  2021-03-15\n",
      "2                                DRUGS  PF_HOME_LA  SEIZED_FROM  2020-04-22\n",
      "3                               VIDEOS  PF_HOME_LA  SEIZED_FROM  2020-04-22\n",
      "==========================================================================================\n",
      "\n",
      "File: Person_Person_Rel.csv\n",
      "Dataframe head:  :START_ID(Person) :END_ID(Person)                :TYPE  \\\n",
      "0                KS              PF       ACCOMPANIED_BY   \n",
      "1                KS              CA       ACCOMPANIED_BY   \n",
      "2                KS              TD       ACCOMPANIED_BY   \n",
      "3                PF              RF  FAMILY_RELATIONSHIP   \n",
      "4                PF              CA       ACCOMPANIED_BY   \n",
      "5                PF              TD       ACCOMPANIED_BY   \n",
      "6                DS              SS  FAMILY_RELATIONSHIP   \n",
      "7                DS              KS  FAMILY_RELATIONSHIP   \n",
      "8                SS              KS  FAMILY_RELATIONSHIP   \n",
      "\n",
      "         relationshipType  \n",
      "0       Last Known Person  \n",
      "1  Fellow Student helping  \n",
      "2  Fellow Student helping  \n",
      "3                  Father  \n",
      "4             Walked with  \n",
      "5             Walked with  \n",
      "6                  Spouse  \n",
      "7                  Mother  \n",
      "8                  Father  \n",
      "==========================================================================================\n",
      "\n",
      "File: Location.csv\n",
      "Dataframe head:               id                            name  \\\n",
      "0       PARTY_LOC        Crandall Way Party House   \n",
      "1       MUIR_HALL           Muir Hall (KS's Dorm)   \n",
      "2     SANTA_LUCIA    Santa Lucia Hall (PF's Dorm)   \n",
      "3         RF_HOME               Ruben Flores Home   \n",
      "4      PF_HOME_LA                Paul Flores Home   \n",
      "5   EXCAVATION_16      Cal Poly Hillside Dig Site   \n",
      "6  MONTEREY_COURT  Monterey County Superior Court   \n",
      "\n",
      "                            type          address             city  \n",
      "0           Off-Campus Residence              NaN  San Luis Obispo  \n",
      "1                      Dormitory  Cal Poly Campus  San Luis Obispo  \n",
      "2                      Dormitory  Cal Poly Campus  San Luis Obispo  \n",
      "3  Primary Residence/Burial Site      White Court    Arroyo Grande  \n",
      "4              Suspect Residence              NaN        San Pedro  \n",
      "5                    Search Site  Cal Poly Campus  San Luis Obispo  \n",
      "6                    Legal Venue              NaN          Salinas  \n",
      "==========================================================================================\n",
      "\n",
      "File: Person_Location_Rel.csv\n",
      "Dataframe head:  :START_ID(Person) :END_ID(Location)              :TYPE        date      time\n",
      "0                KS         PARTY_LOC  ATTENDED_PARTY_AT  1996-05-24  22:00:00\n",
      "1                KS       SANTA_LUCIA     LAST_SEEN_NEAR  1996-05-25  02:00:00\n",
      "2                PF         PARTY_LOC  ATTENDED_PARTY_AT  1996-05-24       NaN\n",
      "3                CA         PARTY_LOC  ATTENDED_PARTY_AT  1996-05-24       NaN\n",
      "4                TD         PARTY_LOC  ATTENDED_PARTY_AT  1996-05-24       NaN\n",
      "5                PF       SANTA_LUCIA           LIVED_AT  1996-05-25       NaN\n",
      "6                RF           RF_HOME       RESIDENCE_OF         NaN       NaN\n",
      "7                PF        PF_HOME_LA       RESIDENCE_OF         NaN       NaN\n",
      "==========================================================================================\n",
      "\n",
      "File: Person.csv\n",
      "Dataframe head:   id             name               type  \\\n",
      "0  KS    Kristin Smart             Victim   \n",
      "1  PF      Paul Flores   Suspect/Murderer   \n",
      "2  RF     Ruben Flores  Suspect/Accessory   \n",
      "3  DS     Denise Smart             Family   \n",
      "4  SS       Stan Smart             Family   \n",
      "5  CA  Cheryl Anderson            Witness   \n",
      "6  TD        Tim Davis            Witness   \n",
      "7  JH  Jennifer Hudson            Witness   \n",
      "8  MC  Mike McConville            Witness   \n",
      "\n",
      "                                         status         dob  \n",
      "0                       Deceased (Missing Body)  1977-02-20  \n",
      "1                        Convicted (25 to Life)  1977-04-11  \n",
      "2                                     Acquitted  1941-01-01  \n",
      "3                                   Key Witness  1950-01-01  \n",
      "4                                   Key Witness  1948-01-01  \n",
      "5                      Last to see KS before PF         NaN  \n",
      "6                      Last to see KS before PF         NaN  \n",
      "7                         Testimony (Admission)         NaN  \n",
      "8  Related to Suspect (Susan Flores' boyfriend)         NaN  \n",
      "==========================================================================================\n",
      "\n",
      "File: Event.csv\n",
      "Dataframe head:               id                           type                 date  \\\n",
      "0       DISAPPEAR    Last Sighting/Disappearance  1996-05-25 02:00:00   \n",
      "1    DECLARE_DEAD          Legally Declared Dead           2002-05-25   \n",
      "2        DIG_2016            Cal Poly Excavation           2016-09-06   \n",
      "3  SEARCH_RF_HOME  Search Warrant (Ruben Flores)           2021-03-15   \n",
      "4         ARRESTS              Arrests of Flores           2021-04-13   \n",
      "5     TRIAL_START             Trial Commencement           2022-07-18   \n",
      "6       PF_GUILTY            Paul Flores Verdict           2022-10-18   \n",
      "\n",
      "                                         description  \n",
      "0  Kristin was last seen with Paul Flores near hi...  \n",
      "1  Declared dead on the 6th anniversary of her di...  \n",
      "2  Sheriff's Office and FBI dug on Cal Poly hills...  \n",
      "3          Cadaver dogs and GPR used under the deck.  \n",
      "4  Paul charged with Murder, Ruben charged with A...  \n",
      "5  Trial started in Monterey County after venue c...  \n",
      "6   Paul Flores found Guilty of First-Degree Murder.  \n",
      "==========================================================================================\n",
      "\n",
      "File: Case_Related_Rel.csv\n",
      "Dataframe head:  :START_ID(Person) :END_ID(Case)                :TYPE    outcome\n",
      "0                KS       CASE_KS            VICTIM_IN        NaN\n",
      "1                PF       CASE_KS           SUSPECT_IN  Convicted\n",
      "2                RF       CASE_KS           ACCUSED_IN  Acquitted\n",
      "3                DS       CASE_KS  FILED_CIVIL_SUIT_IN        NaN\n",
      "4                SS       CASE_KS  FILED_CIVIL_SUIT_IN        NaN\n",
      "==========================================================================================\n",
      "\n",
      "File: Case.csv\n",
      "Dataframe head:        id                     name               status  dateOpened\n",
      "0  CASE_KS  Murder of Kristin Smart  Solved (Conviction)  1996-05-27\n",
      "==========================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_path = Path(\"./L6-7_data\")\n",
    "data = [(file.name, pd.read_csv(file)) for file in data_path.glob(\"*.csv\")]\n",
    "\n",
    "data_str = \"\"\n",
    "for name, df in data:\n",
    "    data_str += f\"File: {name}\\nDataframe head:{df}\\n\" + \"=\" * 90 + \"\\n\\n\"\n",
    "\n",
    "# The names and dataframes for each file\n",
    "print(data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bccdf2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: An Example Knowledge Graph Schema\n",
    "\n",
    "The following creates an example knowledge graph schema, and instantiates it in your Neo4j graph DB instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793746a",
   "metadata": {},
   "source": [
    "### First, a tool for executing Cypher queries in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5492c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "# Tool function to execute Cypher queries\n",
    "def execute_cypher_query(query_str: str, description: str = \"Executing query\", verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Executes a Cypher query on the Neo4j database.\n",
    "\n",
    "    Args:\n",
    "        query_str: The Cypher query to execute\n",
    "        description: A description of what the query does\n",
    "\n",
    "    Returns:\n",
    "        A string describing the result of the query execution\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EXECUTING CYPHER QUERY: {description}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Query:\\n{query_str}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "    # Parse the query into individual statements if needed\n",
    "    queries = \" \".join(\n",
    "        [q for q in query_str.splitlines() if not q.strip().startswith(\"//\")]\n",
    "    )\n",
    "    queries = [q.strip() + \";\" for q in queries.split(\";\") if q.strip()]\n",
    "\n",
    "    nodes_created = 0\n",
    "    relationships_created = 0\n",
    "    properties_set = 0\n",
    "    labels_added = 0\n",
    "    indexes_added = 0\n",
    "    constraints_added = 0\n",
    "    response_parts = []\n",
    "\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        for query in queries:\n",
    "            try:\n",
    "                result = session.run(query)\n",
    "                summary = result.consume()\n",
    "\n",
    "                nodes_created += summary.counters.nodes_created\n",
    "                relationships_created += summary.counters.relationships_created\n",
    "                properties_set += summary.counters.properties_set\n",
    "                labels_added += summary.counters.labels_added\n",
    "                indexes_added += summary.counters.indexes_added\n",
    "                constraints_added += summary.counters.constraints_added\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error executing query: {type(e).__name__}: {str(e)}\"\n",
    "                print(error_msg)\n",
    "                if \"driver\" in locals():\n",
    "                    driver.close()\n",
    "                return error_msg\n",
    "    driver.close()\n",
    "    response_parts.append(f\"Nodes created: {nodes_created}\")\n",
    "    response_parts.append(f\"Relationships created: {relationships_created}\")\n",
    "    response_parts.append(f\"Properties set: {properties_set}\")\n",
    "    response_parts.append(f\"Labels added: {labels_added}\")\n",
    "    response_parts.append(f\"Indexes added: {indexes_added}\")\n",
    "    response_parts.append(f\"Constraints added: {constraints_added}\")\n",
    "\n",
    "    response = \"\\n\".join(response_parts)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"QUERY EXECUTION COMPLETE\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ba919",
   "metadata": {},
   "source": [
    "### An example schema\n",
    "\n",
    "This just sets up the knowledge graph structure, it doesn't ingest any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4fac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXECUTING CYPHER QUERY: Creating knowledge graph schema\n",
      "================================================================================\n",
      "Query:\n",
      "\n",
      "// === NODE CONSTRAINTS (IDs unique + present) ===\n",
      "CREATE CONSTRAINT case_id_unique IF NOT EXISTS\n",
      "FOR (c:Case) REQUIRE c.id IS UNIQUE;\n",
      "CREATE CONSTRAINT case_id_exists IF NOT EXISTS\n",
      "FOR (c:Case) REQUIRE c.id IS NOT NULL;\n",
      "CREATE CONSTRAINT event_id_unique IF NOT EXISTS\n",
      "FOR (e:Event) REQUIRE e.id IS UNIQUE;\n",
      "CREATE CONSTRAINT event_id_exists IF NOT EXISTS\n",
      "FOR (e:Event) REQUIRE e.id IS NOT NULL;\n",
      "CREATE CONSTRAINT evidence_id_unique IF NOT EXISTS\n",
      "FOR (ev:Evidence) REQUIRE ev.id IS UNIQUE;\n",
      "CREATE CONSTRAINT evidence_id_exists IF NOT EXISTS\n",
      "FOR (ev:Evidence) REQUIRE ev.id IS NOT NULL;\n",
      "CREATE CONSTRAINT location_id_unique IF NOT EXISTS\n",
      "FOR (l:Location) REQUIRE l.id IS UNIQUE;\n",
      "CREATE CONSTRAINT location_id_exists IF NOT EXISTS\n",
      "FOR (l:Location) REQUIRE l.id IS NOT NULL;\n",
      "CREATE CONSTRAINT person_id_unique IF NOT EXISTS\n",
      "FOR (p:Person) REQUIRE p.id IS UNIQUE;\n",
      "CREATE CONSTRAINT person_id_exists IF NOT EXISTS\n",
      "FOR (p:Person) REQUIRE p.id IS NOT NULL;\n",
      "\n",
      "// === RELATIONSHIP PROPERTY EXISTENCE (Enterprise Edition) ===\n",
      "// Person-Person\n",
      "CREATE CONSTRAINT accompanied_by_relationshipType_exists IF NOT EXISTS\n",
      "FOR ()-[r:ACCOMPANIED_BY]-() REQUIRE r.relationshipType IS NOT NULL;\n",
      "\n",
      "// Person-Location (carry dates; time may be optional)\n",
      "CREATE CONSTRAINT attended_party_at_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:ATTENDED_PARTY_AT]-() REQUIRE r.date IS NOT NULL;\n",
      "CREATE CONSTRAINT last_seen_near_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:LAST_SEEN_NEAR]-() REQUIRE r.date IS NOT NULL;\n",
      "CREATE CONSTRAINT lived_at_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:LIVED_AT]-() REQUIRE r.date IS NOT NULL;\n",
      "CREATE CONSTRAINT residence_of_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:RESIDENCE_OF]-() REQUIRE r.date IS NOT NULL;\n",
      "\n",
      "// Evidence-Location (carry dates)\n",
      "CREATE CONSTRAINT found_at_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:FOUND_AT]-() REQUIRE r.date IS NOT NULL;\n",
      "CREATE CONSTRAINT seized_from_date_exists IF NOT EXISTS\n",
      "FOR ()-[r:SEIZED_FROM]-() REQUIRE r.date IS NOT NULL;\n",
      "\n",
      "// Case-related edges typically include optional outcome metadata\n",
      "CREATE INDEX person_name IF NOT EXISTS FOR (p:Person) ON (p.name);\n",
      "CREATE INDEX location_name IF NOT EXISTS FOR (l:Location) ON (l.name);\n",
      "CREATE INDEX case_name IF NOT EXISTS FOR (c:Case) ON (c.name);\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY EXECUTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Nodes created: 0\n",
      "Relationships created: 0\n",
      "Properties set: 0\n",
      "Labels added: 0\n",
      "Indexes added: 3\n",
      "Constraints added: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nodes created: 0\\nRelationships created: 0\\nProperties set: 0\\nLabels added: 0\\nIndexes added: 3\\nConstraints added: 17'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_str = \"\"\"\n",
    "// === NODE CONSTRAINTS (IDs unique + present) ===\n",
    "CREATE CONSTRAINT case_id_unique IF NOT EXISTS\n",
    "FOR (c:Case) REQUIRE c.id IS UNIQUE;\n",
    "CREATE CONSTRAINT case_id_exists IF NOT EXISTS\n",
    "FOR (c:Case) REQUIRE c.id IS NOT NULL;\n",
    "CREATE CONSTRAINT event_id_unique IF NOT EXISTS\n",
    "FOR (e:Event) REQUIRE e.id IS UNIQUE;\n",
    "CREATE CONSTRAINT event_id_exists IF NOT EXISTS\n",
    "FOR (e:Event) REQUIRE e.id IS NOT NULL;\n",
    "CREATE CONSTRAINT evidence_id_unique IF NOT EXISTS\n",
    "FOR (ev:Evidence) REQUIRE ev.id IS UNIQUE;\n",
    "CREATE CONSTRAINT evidence_id_exists IF NOT EXISTS\n",
    "FOR (ev:Evidence) REQUIRE ev.id IS NOT NULL;\n",
    "CREATE CONSTRAINT location_id_unique IF NOT EXISTS\n",
    "FOR (l:Location) REQUIRE l.id IS UNIQUE;\n",
    "CREATE CONSTRAINT location_id_exists IF NOT EXISTS\n",
    "FOR (l:Location) REQUIRE l.id IS NOT NULL;\n",
    "CREATE CONSTRAINT person_id_unique IF NOT EXISTS\n",
    "FOR (p:Person) REQUIRE p.id IS UNIQUE;\n",
    "CREATE CONSTRAINT person_id_exists IF NOT EXISTS\n",
    "FOR (p:Person) REQUIRE p.id IS NOT NULL;\n",
    "\n",
    "// === RELATIONSHIP PROPERTY EXISTENCE (Enterprise Edition) ===\n",
    "// Person-Person\n",
    "CREATE CONSTRAINT accompanied_by_relationshipType_exists IF NOT EXISTS\n",
    "FOR ()-[r:ACCOMPANIED_BY]-() REQUIRE r.relationshipType IS NOT NULL;\n",
    "\n",
    "// Person-Location (carry dates; time may be optional)\n",
    "CREATE CONSTRAINT attended_party_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:ATTENDED_PARTY_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT last_seen_near_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:LAST_SEEN_NEAR]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT lived_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:LIVED_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT residence_of_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:RESIDENCE_OF]-() REQUIRE r.date IS NOT NULL;\n",
    "\n",
    "// Evidence-Location (carry dates)\n",
    "CREATE CONSTRAINT found_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:FOUND_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT seized_from_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:SEIZED_FROM]-() REQUIRE r.date IS NOT NULL;\n",
    "\n",
    "// Case-related edges typically include optional outcome metadata\n",
    "CREATE INDEX person_name IF NOT EXISTS FOR (p:Person) ON (p.name);\n",
    "CREATE INDEX location_name IF NOT EXISTS FOR (l:Location) ON (l.name);\n",
    "CREATE INDEX case_name IF NOT EXISTS FOR (c:Case) ON (c.name);\n",
    "\"\"\"\n",
    "\n",
    "execute_cypher_query(query_str, description=\"Creating knowledge graph schema\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1312beb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Or ask an agentic system to build it for us!\n",
    "\n",
    "Note: this is not guaranteed to converge, and it may take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ab16a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'query_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     58\u001b[39m schema_planner = AssistantAgent(\n\u001b[32m     59\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mSchemaPlanner\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     60\u001b[39m     system_message=schema_planner_message,\n\u001b[32m     61\u001b[39m     model_client=client,\n\u001b[32m     62\u001b[39m )\n\u001b[32m     64\u001b[39m query_tool = \u001b[38;5;28;01mlambda\u001b[39;00m query_str, description: execute_cypher_query(\n\u001b[32m     65\u001b[39m     query_str,\n\u001b[32m     66\u001b[39m     description,\n\u001b[32m     67\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Enable verbose for detailed output of queries\u001b[39;00m\n\u001b[32m     68\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m schema_creator = \u001b[43mAssistantAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSchemaCreator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_creator_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Run the agentic system\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_knowledge_graph\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CSC480/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py:783\u001b[39m, in \u001b[36mAssistantAgent.__init__\u001b[39m\u001b[34m(self, name, model_client, tools, workbench, handoffs, model_context, description, system_message, model_client_stream, reflect_on_tool_use, max_tool_iterations, tool_call_summary_format, tool_call_summary_formatter, output_content_type, output_content_type_format, memory, metadata)\u001b[39m\n\u001b[32m    781\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    782\u001b[39m         description = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m     \u001b[38;5;28mself\u001b[39m._tools.append(\u001b[43mFunctionTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported tool type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tool)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CSC480/.venv/lib/python3.12/site-packages/autogen_core/tools/_function_tool.py:98\u001b[39m, in \u001b[36mFunctionTool.__init__\u001b[39m\u001b[34m(self, func, description, name, global_imports, strict)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._func = func\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m._global_imports = global_imports\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28mself\u001b[39m._signature = \u001b[43mget_typed_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m func_name = name \u001b[38;5;129;01mor\u001b[39;00m func.func.\u001b[34m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, functools.partial) \u001b[38;5;28;01melse\u001b[39;00m name \u001b[38;5;129;01mor\u001b[39;00m func.\u001b[34m__name__\u001b[39m\n\u001b[32m    100\u001b[39m args_model = args_base_model_from_signature(func_name + \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._signature)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CSC480/.venv/lib/python3.12/site-packages/autogen_core/_function_utils.py:52\u001b[39m, in \u001b[36mget_typed_signature\u001b[39m\u001b[34m(call)\u001b[39m\n\u001b[32m     45\u001b[39m func_call = call.func \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(call, partial) \u001b[38;5;28;01melse\u001b[39;00m call\n\u001b[32m     46\u001b[39m type_hints = typing.get_type_hints(func_call, globalns, include_extras=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     47\u001b[39m typed_params = [\n\u001b[32m     48\u001b[39m     inspect.Parameter(\n\u001b[32m     49\u001b[39m         name=param.name,\n\u001b[32m     50\u001b[39m         kind=param.kind,\n\u001b[32m     51\u001b[39m         default=param.default,\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         annotation=\u001b[43mtype_hints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m     53\u001b[39m     )\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m signature.parameters.values()\n\u001b[32m     55\u001b[39m ]\n\u001b[32m     56\u001b[39m return_annotation = type_hints.get(\u001b[33m\"\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m\"\u001b[39m, inspect.Signature.empty)\n\u001b[32m     57\u001b[39m typed_signature = inspect.Signature(typed_params, return_annotation=return_annotation)\n",
      "\u001b[31mKeyError\u001b[39m: 'query_str'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Configure Azure OpenAI client\n",
    "azure_deployment = \"gpt-5-mini\"  # Replace with your deployment name\n",
    "api_version = \"2024-12-01-preview\"\n",
    "azure_endpoint = \"https://your-resource.openai.azure.com/\"  # Replace with your endpoint\n",
    "api_key = os.getenv(\"AZURE_SUBSCRIPTION_KEY\")  # Set this environment variable\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY environment variable not set.\")\n",
    "\n",
    "client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=\"gpt-5-mini\",\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "schema_planner_message = \"\"\"\n",
    "You are a Graph Database Schema Planner. Your job is to analyze the provided data \n",
    "and design an optimal graph database schema for Neo4j.\n",
    "\n",
    "Given the data structure, you should:\n",
    "1. Identify which CSV files should become node types\n",
    "2. Identify which CSV files represent relationships between nodes\n",
    "3. Plan constraints and indexes for efficient querying\n",
    "4. Explain your reasoning clearly\n",
    "5. Consider feedback from the User Proxy\n",
    "\n",
    "Files ending in \"_Rel.csv\" typically represent relationships between entities.\n",
    "Files without \"_Rel\" typically represent node entities.\n",
    "\n",
    "Once you have planned the schema and the User Proxy approves, say \"SCHEMA_READY\" to proceed.\n",
    "\"\"\"\n",
    "\n",
    "schema_creator_message = \"\"\"\n",
    "You are a Graph Database Schema Creator. You receive schema plans and create them\n",
    "in Neo4j using Cypher queries.\n",
    "\n",
    "Your tasks:\n",
    "1. Clear any existing data (use MATCH (n) DETACH DELETE n)\n",
    "2. Create constraints for unique identifiers (use CREATE CONSTRAINT ... IF NOT EXISTS)\n",
    "3. Create indexes for frequently queried properties\n",
    "\n",
    "Use the execute_query tool to run your cypher queries. Provide clear descriptions\n",
    "of what each query does.\n",
    "\n",
    "After creating the schema successfully, say \"SCHEMA_CREATED\" to finish.\n",
    "\"\"\"\n",
    "\n",
    "schema_planner = AssistantAgent(\n",
    "    name=\"SchemaPlanner\",\n",
    "    system_message=schema_planner_message,\n",
    "    model_client=client,\n",
    ")\n",
    "\n",
    "query_tool = lambda query_str, description: execute_cypher_query(\n",
    "    query_str,\n",
    "    description,\n",
    "    verbose=True,  # Enable verbose for detailed output of queries\n",
    ")\n",
    "\n",
    "schema_creator = AssistantAgent(\n",
    "    name=\"SchemaCreator\",\n",
    "    system_message=schema_creator_message,\n",
    "    model_client=client,\n",
    "    tools=[query_tool],\n",
    ")\n",
    "\n",
    "\n",
    "# Run the agentic system\n",
    "async def build_knowledge_graph():\n",
    "    \"\"\"\n",
    "    Runs the agentic system to plan and create schema in Neo4j using round robin.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STARTING AGENTIC KNOWLEDGE GRAPH SCHEMA DESIGN\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    termination = TextMentionTermination(\"SCHEMA_CREATED\")\n",
    "    groupchat = RoundRobinGroupChat(\n",
    "        [schema_planner, schema_creator],\n",
    "        max_turns=100,\n",
    "        termination_condition=termination,\n",
    "    )\n",
    "\n",
    "    # Create the initial task with the data_str (from earlier cell) context\n",
    "    task = f\"\"\"\n",
    "    We need to design and create a Knowledge Graph schema in Neo4j from the following data:\n",
    "\n",
    "    {data_str}\n",
    "\n",
    "    UserProxy: Please review the data and guide the schema design process.\n",
    "    SchemaPlanner: Analyze this data and design an optimal graph schema.\n",
    "    SchemaCreator: Once the schema is approved, create it in Neo4j.\n",
    "\n",
    "    Work together in round robin fashion to complete this task step by step.\n",
    "    \"\"\"\n",
    "\n",
    "    result: TaskResult = await groupchat.run(task=task)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KNOWLEDGE GRAPH SCHEMA DESIGN COMPLETE\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Execute the agentic system\n",
    "result = await build_knowledge_graph()\n",
    "\n",
    "# Print out all messages from the agents\n",
    "for message in result.messages:\n",
    "    print(f\"{message.content}\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321154e",
   "metadata": {},
   "source": "---\n\n## Part 4: Reflection\n\n##### What worked well in the schema creation and data inspection?\n\nThe execute_cypher_query helper function worked exceptionally well by providing clear feedback on nodes created, relationships created, properties set, and constraints/indexes added, which made debugging and verification straightforward. The Neo4j Python driver connection was smooth and reliable, and using pandas to preview the CSVs made it easy to understand the data structure and identify node types versus relationships. The IF NOT EXISTS clause in Cypher allowed safe re-running of schema creation queries during iterative development, and the logical separation of node entities from relationship CSVs made the graph model intuitive and aligned well with Neo4j's property graph paradigm.\n\n##### What struggled?\n\nSeveral challenges emerged including Enterprise Edition relationship property constraints that silently fail in Community Edition, the AutoGen-based agentic approach encountering a KeyError due to incorrect tool function signature handling, and data quality issues with missing date/time values that could violate NOT NULL constraints. Managing many different relationship types each requiring different constraints became tedious and error-prone, and while IF NOT EXISTS prevented duplicate constraints, it didn't validate whether constraints were actually created successfully due to edition limitations.\n\n##### Manual Cypher vs. Agentic Schema Creation\n\nManual Cypher provides full control and transparency with faster execution for small schemas, high reproducibility, and easier debugging, making it ideal for production systems where correctness and performance are critical. Agentic schema creation offers less transparency and slower performance due to LLM inference latency with potential non-deterministic results, but can be useful for exploring new domains or rapid prototyping. The practical recommendation is to use manual Cypher for production systems and consider agentic approaches only for educational exploration or prototyping, with a hybrid approach of using LLM-generated suggestions that you manually review and refine potentially offering the best balance."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}